{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d8a28ce",
   "metadata": {},
   "source": [
    "###Assignment 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aa5bde",
   "metadata": {},
   "source": [
    "##1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "849f7c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules \n",
    "import requests\n",
    "import xml.dom.minidom as m\n",
    "import xml.etree.ElementTree as et\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "055cf83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(disease):\n",
    "    r = requests.get(f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term={disease}+AND+2022[pdat]&retmax=1000&retmode=xml\")\n",
    "    time.sleep(1)\n",
    "    doc = m.parseString(r.text)\n",
    "    PubmedId = doc.getElementsByTagName('Id')\n",
    "    IdList = []\n",
    "    for i in range(len(PubmedId)):\n",
    "        IdList.append(PubmedId[i].firstChild.data)\n",
    "\n",
    "    return IdList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36e088ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_id(\"Alzheimers\") + get_id(\"Cancer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4764c7",
   "metadata": {},
   "source": [
    "Finding an overlap between two sets of papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caced5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_papers(disease1,disease2):\n",
    "    IdList1 = get_id(disease1)\n",
    "    IdList2 = get_id(disease2)\n",
    "    set1 = set(IdList1)\n",
    "    set2 = set(IdList2)\n",
    "    overlap = list(set1&set2)\n",
    "    if len(overlap) == 0:\n",
    "        print(\"There is no overlap in the two sets of papers\")\n",
    "    elif len(overlap) == 1:\n",
    "        print(f\"There is a overlap in the two sets of papers, the Pubmed Id is {overlap[0]}\")\n",
    "        return overlap[0]\n",
    "    else:\n",
    "        print(f\"There are overlaps in the two sets of papers, the Pubmed Ids are{overlap}\")\n",
    "        return overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b944e64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are overlaps in the two sets of papers, the Pubmed Ids are['36321363', '36321615']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['36321363', '36321615']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_papers('Alzheimers','cancer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2593ad9",
   "metadata": {},
   "source": [
    "Finding the Metadata of the papers in Alzheimers and Cancer sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6294dd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_metadata(disease):\n",
    "    PubmedIdList = get_id(disease)\n",
    "    disease_dictionary = {}\n",
    "    for PubmedId in PubmedIdList:\n",
    "        time.sleep(1)\n",
    "        r = requests.post(f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&retmode=xml&id={int(PubmedId)}\")\n",
    "        doc = m.parseString(r.text)\n",
    "\n",
    "        ArticleTitle = doc.getElementsByTagName('ArticleTitle')\n",
    "        Title = \"\"\n",
    "        if len(ArticleTitle) > 0:\n",
    "            for elm in ArticleTitle:\n",
    "                for textmessage in elm.childNodes:\n",
    "                    try:\n",
    "                        Title += textmessage._get_wholeText()\n",
    "                        # reference: https://docs.python.org/3/tutorial/errors.html\n",
    "                        Title = et.tostring(Title, method = \"text\").decode()\n",
    "                    \n",
    "                    except AttributeError: \n",
    "                        for subnode in textmessage.childNodes:\n",
    "                            if subnode.nodeType == m.Node.TEXT_NODE:\n",
    "                                Title += subnode.data\n",
    "     \n",
    "        AbstractText = doc.getElementsByTagName('AbstractText')\n",
    "        Abstract = \"\"\n",
    "        if len(AbstractText) > 0:\n",
    "            for elm in AbstractText:\n",
    "                for textmessage in elm.childNodes:\n",
    "                    try:\n",
    "                        Abstract += textmessage._get_wholeText()\n",
    "                        Abstract = et.tostring(Abstract, method = \"text\").decode()\n",
    "                    except AttributeError: \n",
    "                        for subnode in textmessage.childNodes:\n",
    "                            if subnode.nodeType == m.Node.TEXT_NODE:\n",
    "                                Abstract += subnode.data\n",
    "\n",
    "      \n",
    "        MeshHeading = doc.getElementsByTagName('MeshHeading')\n",
    "        ArticleMeshTerms = []\n",
    "        if len(MeshHeading) > 0:\n",
    "            try:\n",
    "                for i in MeshHeading:\n",
    "                    ArticleMeshTerms.append(i.firstChild.childNodes[0].nodeValue)\n",
    "            except AttributeError: pass\n",
    "            \n",
    "        disease_dictionary[PubmedId] = {\n",
    "            'ArticleTitle': Title,\n",
    "            'ArticleAbstract': Abstract,\n",
    "            'Query': disease,\n",
    "            'Mesh': ArticleMeshTerms\n",
    "        }\n",
    "        \n",
    "    return  disease_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532c424f",
   "metadata": {},
   "source": [
    "Saving JSON files separatly of Alzheimers & Cancer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec5d8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "alz_data = find_metadata('Alzheimers')\n",
    "cancer_data = find_metadata('cancer')\n",
    "\n",
    "# alz_data into a JSON file paper.json.\n",
    "with open('alzheimers.json','w') as f:\n",
    "    json.dump(alz_data,f)\n",
    "    \n",
    "# cancer_data into a JSON file paper.json.\n",
    "with open('cancer.json', 'w') as f:\n",
    "    json.dump(cancer_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8e3721",
   "metadata": {},
   "outputs": [],
   "source": [
    "alz_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03909bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c275bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "both_papers_data = find_metadata('Alzheimers')\n",
    "cancer_data = find_metadata('cancer')\n",
    "both_papers_data.update(cancer_data)\n",
    "\n",
    "with open('combined.json','w') as f:\n",
    "    json.dump(both_papers_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c90d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(both_papers_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379f0640",
   "metadata": {},
   "source": [
    "##2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b285a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install pytorch torchvision -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92c848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1198d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "# load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('allenai/specter')\n",
    "model = AutoModel.from_pretrained('allenai/specter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6025a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da86758",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"alzheimers.json\") as f:\n",
    "    alz_meta = json.load(f)\n",
    "\n",
    "alz_data_format = pd.DataFrame.from_dict(alz_meta, orient = 'index') \n",
    "alz_data_format.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9b6bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cancer.json\") as f:\n",
    "    cancer_meta = json.load(f)\n",
    "\n",
    "cancer_data_frame = pd.DataFrame.from_dict(cancer_meta, orient = 'index') \n",
    "cancer_data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aea257",
   "metadata": {},
   "outputs": [],
   "source": [
    "both_papers = pd.concat([alz_data_format,cancer_data_frame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5a1fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "both_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7d194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read JSON file using the open function.\n",
    "with open('combined.json') as f:\n",
    "    both_papers_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7e809d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [paper[\"ArticleTitle\"] + tokenizer.sep_token + paper[\"ArticleAbstract\"] for paper in both_papers_data.values()]\n",
    "inputs = tokenizer([data[0]], padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "result = model(**inputs)\n",
    "embed_total = result.last_hidden_state[:, 0, :].detach().numpy()\n",
    "\n",
    "for i in range(1,len(data)):\n",
    "    inputs = tokenizer([data[i]], padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "    result = model(**inputs)\n",
    "    embed = result.last_hidden_state[:, 0, :].detach().numpy()\n",
    "    embed_total = np.concatenate((embed_total, embed),axis = 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67c6dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aecac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 3 principal components. \n",
    "pca = decomposition.PCA(n_components=3)\n",
    "embed_pca = pd.DataFrame(\n",
    "    pca.fit_transform(embed_total),\n",
    "    columns=['PC0', 'PC1', 'PC2']\n",
    ")\n",
    "embed_pca[\"Query\"] = [paper[\"Query\"] for paper in both_papers_data.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f7fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368fe7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotnine as p9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325e4b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PC0 vs PC1\n",
    "(p9.ggplot(data = embed_pca, mapping = p9.aes(x='PC0', y='PC1'))\n",
    "+ p9.geom_point(p9.aes(x = 'PC0', y = 'PC1', color = 'Query'))\n",
    "+ p9.labs(title = \"PC0 vs PC1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b67f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PC0 vs PC2\n",
    "(p9.ggplot(data = embed_pca, mapping = p9.aes(x='PC0', y='PC2'))\n",
    "+ p9.geom_point(p9.aes(x = 'PC0', y = 'PC2', color = 'Query'))\n",
    "+ p9.labs(title = \"PC0 vs PC2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bad473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PC1 vs PC2\n",
    "(p9.ggplot(data = embed_pca, mapping = p9.aes(x='PC1', y='PC2'))\n",
    "+ p9.geom_point(p9.aes(x = 'PC1', y = 'PC2', color = 'Query'))\n",
    "+ p9.labs(title = \"PC1 vs PC2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f6a221",
   "metadata": {},
   "source": [
    "##3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d73dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_with_explicit_Eulers(s0,i0,r0,B,g, tMax):\n",
    "\n",
    "    #Initialize parameters and arrays  \n",
    "    numSteps=1000\n",
    "    tStep=tMax/numSteps\n",
    "    N=s0+i0+r0\n",
    "    t=[0]*(numSteps+1)\n",
    "    s=[0]*(numSteps+1)\n",
    "    i=[0]*(numSteps+1)\n",
    "    t[0]=0\n",
    "    s[0]=s0\n",
    "    i[0]=i0\n",
    "    peak_not_reached=False\n",
    "    \n",
    "    #Calculate i over time range\n",
    "    for j in range(1,numSteps+1):\n",
    "        t[j]=t[j-1]+tStep\n",
    "        s[j]=s[j-1]+(tStep)*(-B/N*s[j-1]*i[j-1])\n",
    "        i[j]=i[j-1]+(tStep)*(B/N*s[j-1]*i[j-1]-g*i[j-1])\n",
    "        #Check if peak reached\n",
    "        if (i[j]<i[j-1] and not peak_not_reached):\n",
    "            peak_day=t[j-1] #round(t[j-1]) to the nearest integer/day \n",
    "            peak_infections=round(i[j-1])\n",
    "            peak_not_reached=True\n",
    "\n",
    "    plt.plot(t,i,label=\"Infected People\")\n",
    "    return peak_day,peak_infections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af018476",
   "metadata": {},
   "outputs": [],
   "source": [
    "[peak_day,peak_infections]=plot_with_explicit_Eulers(13399,1,0,2,1,30)\n",
    "print(\"Peak day: \", peak_day)\n",
    "print(\"Peak infections: \", peak_infections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff9b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "Bs=[]\n",
    "gs=[]\n",
    "peak_days=[]\n",
    "peak_infections=[]\n",
    "\n",
    "for B in np.arange(1.8,2.2,0.05):\n",
    "    for g in np.arange(0.9,1.1,0.02):\n",
    "        [peak_day,peak_infection]=plot_with_explicit_Eulers(13399,1,0,B,g,100)\n",
    "        Bs.append(B)\n",
    "        gs.append(g)\n",
    "        peak_days.append(peak_day)\n",
    "        peak_infections.append(peak_infection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f90ef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts={\"B\":Bs,\"g\":gs,\"peak_days\":peak_days,\"peak_infections\":peak_infections}\n",
    "data=pd.DataFrame(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edeffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#infection time in days\n",
    "sns.set()\n",
    "sns.heatmap(data.pivot(\"B\",\"g\",\"peak_days\"))\n",
    "plt.title(\"Heatmap of peak infection time in days as a function of Beta and gamma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34100a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#infected people in days\n",
    "sns.set()\n",
    "sns.heatmap(data.pivot(\"B\",\"g\",\"peak_infections\"))\n",
    "plt.title(\"Heatmap of peak number of infected people in days as a function of Beta and gamma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931ef0bb",
   "metadata": {},
   "source": [
    "##4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a90746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7ddd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/polina/Desktop/Life Expectancy Data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aa1a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eea6ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20851c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b699a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking for null value in the data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a457619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the Null Values with mean values of the data\n",
    "from sklearn.impute import SimpleImputer\n",
    "#reference: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html\n",
    "imputer=SimpleImputer(missing_values=np.nan,strategy='mean',fill_value=None)\n",
    "df['Life expectancy ']=imputer.fit_transform(df[['Life expectancy ']])\n",
    "df['Adult Mortality']=imputer.fit_transform(df[['Adult Mortality']])\n",
    "df['Alcohol']=imputer.fit_transform(df[['Alcohol']])\n",
    "df['Hepatitis B']=imputer.fit_transform(df[['Hepatitis B']])\n",
    "df[' BMI ']=imputer.fit_transform(df[[' BMI ']])\n",
    "df['Polio']=imputer.fit_transform(df[['Polio']])\n",
    "df['Total expenditure']=imputer.fit_transform(df[['Total expenditure']])\n",
    "df['Diphtheria ']=imputer.fit_transform(df[['Diphtheria ']])\n",
    "df['GDP']=imputer.fit_transform(df[['GDP']])\n",
    "df['Population']=imputer.fit_transform(df[['Population']])\n",
    "df[' thinness  1-19 years']=imputer.fit_transform(df[[' thinness  1-19 years']])\n",
    "df[' thinness 5-9 years']=imputer.fit_transform(df[[' thinness 5-9 years']])\n",
    "df['Income composition of resources']=imputer.fit_transform(df[['Income composition of resources']])\n",
    "df['Schooling']=imputer.fit_transform(df[['Schooling']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfb3e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking for null value in the data after fitting\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c6f81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing/Renaming the columns for easy access.\n",
    "df = df.rename(columns={'Country': 'country', 'Year': 'year', 'Status': 'status', 'Life expectancy ': 'life_expectancy', 'Adult Mortality': 'adult_mortality',\n",
    "       'infant deaths':'infant_death', 'Alcohol':'alcohol', 'percentage expenditure': 'percentage_expenditure', 'Hepatitis B':'Hepatitis_b',\n",
    "       'Measles ':'measles', ' BMI ':'bmi', 'under-five deaths ':'under_five_deaths', 'Polio':'polio', 'Total expenditure': 'total_expenditure','Diphtheria ':'diphtheria', ' HIV/AIDS':'hiv_Aids', 'GDP':'gdp', 'Population':'population',\n",
    "       ' thinness  1-19 years':'thinness_1_to_19', ' thinness 5-9 years':'thinness_5_to_9',\n",
    "       'Income composition of resources':'income_composition_of_resources', 'Schooling': 'schooling'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e8ffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking for columns after rename\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d04f38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of Life Expectancy according to the age\n",
    "fig = px.histogram(df, x = 'life_expectancy')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b450c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing the life expectancy of Developing and Developed Countries\n",
    "fig = px.violin(df, x= 'status', y= 'life_expectancy',\n",
    "                color = 'status',box = True,title='Life Expectancy on the Basis of Country Status')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0bd6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Country Wise Life Expectancy over the years\n",
    "fig = px.line((df.sort_values(by = 'year')), x = 'year', y = 'life_expectancy',\n",
    "    animation_frame= 'country',animation_group='year',color='country',\n",
    "    markers=True,title='<b>Country Wise Life Expectancy over the years')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9b58c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df = px.data.gapminder()\n",
    "country_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edf7db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Life Expectancy over the World Map\n",
    "map_fig = px.scatter_geo(country_df,locations = 'iso_alpha', projection = 'orthographic', \n",
    "                         opacity = 0.8, color = 'country', hover_name = 'country', \n",
    "                         hover_data = ['lifeExp', 'year'],template = 'plotly_dark',title = '<b>Life Expectancy over the World Map')\n",
    "map_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f842a4af",
   "metadata": {},
   "source": [
    "Refrences\n",
    "(Kumar R.(2017).Life Expectancy(WHO).from https://www.kaggle.com/datasets/kumarajarshi/life-expectancy-who))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
